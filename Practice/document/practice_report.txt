In the last practices we have been extracting the data from the files without taking in consideration the tags for the xml files. 
To do so we have used the function "get_doc_content" and we extracted the complete file content using regex.

The extraction and the ranking of the document using the given queries was working correctly and we have tried to have a better accuracy using tuning methods.

For the tag extraction we have created functions to extract the complete tree structure from the files, and store it into a variable.
Before extracting the content, we ask the user to enter the desired tags to be used for ranking.

We used the function "extract_from_tags" and give as arguments the tags, we then looped over all the tags to check if they actually exist in the file and then extract the content.

Once the extraction was completed, we had to adapt the functions for calculating the tf and df as well as the smarltn, smarltc and bm25 fucntions to tak in consideration the 2 cases (by tag, or by whole document). 

The results we have gotten weren't even close to the desired ones, as a result we have merged the 2 functions get_doc_content and extract_from_tags into one single function. Then once the user choses the extraction method :
if by whole document we set the parameter for the extract_from tags function the list ["article"]
if by tags we set the parameter for the function the list tags= ["bdy","p"]  for exemple ....

The final function we have created will return a dicitonnary with all the necessary information to do the ranking: 

If we take only one file to process for exemple yyy.xml with the following content : 

<?xml version="1.0" encoding="UTF-8"?>
<!-- generated by CLiX/Wiki2XML [MPI-Inf, MMCI@UdS] $LastChangedRevision: 92 $ on 16.04.2009 15:20:19[mciao0826] -->
<!DOCTYPE article SYSTEM "../article.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
<header>
<title>Arithmetic mean</title>
<id>612</id>
<revision>
<id>244345277</id>
<timestamp>2008-10-10T10:43:39Z</timestamp>
<contributor>
<username>Ahruman</username>
<id>128625</id>
</contributor>
</revision>
<categories>
<category>Means</category>
<category>Statistics articles linked to the portal</category>
<category>Statistics articles with navigational template</category>
</categories>
</header>

</article>


The dictionnary in will be (if we remove stop words and do the stemming with Porter) :

[
  {'docno': '612',
  'metadata': [
      {'hierarchies': '/article[1]',
       'content':
        'arithmet 612 244345277 2008-10-10t10:43:39z ahruman 128625 statist articl link portal statist articl navig templat', 'indexation': [
            {
              'index':
                 {'arithmet': {'612'}, '612': {'612'}, '244345277': {'612'}, '2008-10-10t10:43:39z': {'612'}, 'ahruman': {'612'}, '128625': {'612'}, 'statist': {'612'}, 'articl': {'612'}, 'link': {'612'}, 'portal': {'612'}, 'navig': {'612'}, 'templat': {'612'}},
              'term_frequency': 
                  {'arithmet': defaultdict(<class 'int'>, {'612': 1}), '612': defaultdict(<class 'int'>, {'612': 1}), '244345277': defaultdict(<class 'int'>, {'612': 1}), '2008-10-10t10:43:39z': defaultdict(<class 'int'>, {'612': 1}), 'ahruman': defaultdict(<class 'int'>, {'612': 1}), '128625': defaultdict(<class 'int'>, {'612': 1}), 'statist': defaultdict(<class 'int'>, {'612': 2}), 'articl': defaultdict(<class 'int'>, {'612': 2}), 'link': defaultdict(<class 'int'>, {'612': 1}), 'portal': defaultdict(<class 'int'>, {'612': 1}), 'navig': defaultdict(<class 'int'>, {'612': 1}), 'templat': defaultdict(<class 'int'>, {'612': 1})}
              }
            ]
      }
  ]
}
]

There are 2 main components : the docno and the metadata. The metadata contains  the hierarchy for the extracted tag, and the indexation. 

The smarltn, smartltc and the bm25 functions have been adapted to be able to use this dictionnary and return the important data that will be used for evaluating using the query. 

The only remaining part of this part is to write with the correct INEX syntax to the result files.

*****   This part is only fo testing purposes   ******

-- In our case, and in order to be able to test the functions without the program taking too much time, we have decided to extract the specific content for a specific tag and not go on the whole tree structure until the tag, we have taken only the tag content. 
For exemple if the user choses to extract using p tag, we give the result for:
                                                                                   /article[1]/bdy[1]/sec[1]/p[1]
                                                                                   /article[1]/bdy[1]/sec[1]/p[2]
                                                                                  /article[1]/bdy[1]/sec[1]/p[3]
                                                                                  /article[1]/bdy[1]/category[1]/sec[1]/element[1]/p[1]
                                                                                  /article[1]/bdy[1]/category[1]/sec[1]/element[1]/p[2]
                                                                                  /article[1]/bdy[1]/category[1]/sec[1]/element[1]/p[3]
                                                                                  /article[1]/bdy[1]/category[1]/sec[1]/element[1]/p[4]

The ranking of all the files (~9800 file) the program takes approximatly 5 minutes.  

Remaining things to do in practice 5:
    1- Write output into the files
    2- Wilkinson94 and Robertson94
    3- Indexing exploiting structure, links and anchors. (Practice 6)

